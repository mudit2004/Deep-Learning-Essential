{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12d8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7838549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b06c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating validation data and scaling data to range (0-1)\n",
    "X_valid, X_train = X_train[:4000], X_train[4000:] / 255.0\n",
    "y_valid, y_train = y_train[:4000], y_train[4000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197d5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a smaller subset for quicker experimentation\n",
    "X_train_small = X_train[:10000]\n",
    "y_train_small = y_train[:10000]\n",
    "X_valid_small = X_valid[:1000]\n",
    "y_valid_small = y_valid[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a216cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to include channel dimension\n",
    "X_train_small = X_train_small.reshape(-1, 28, 28, 1)\n",
    "X_valid_small = X_valid_small.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2cf8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build and compile CNN model\n",
    "def build_compile_cnn_model(learning_rate):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(70, activation='relu'),\n",
    "        keras.layers.Dense(50, activation='relu'),\n",
    "        keras.layers.Dense(20, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN with learning rate: 0.1\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "\n",
      "Training CNN with learning rate: 0.01\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "\n",
      "Training CNN with learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different learning rates\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f'\\nTraining CNN with learning rate: {lr}')\n",
    "    cnn_model = build_compile_cnn_model(lr)\n",
    "    cnn_model_history = cnn_model.fit(X_train_small, y_train_small, validation_data=(X_valid_small, y_valid_small), epochs=10, verbose=0)\n",
    "    \n",
    "    # Evaluate model\n",
    "    test_loss, test_acc = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_probs = cnn_model.predict(X_test)\n",
    "    y_preds = y_probs.argmax(axis=1)\n",
    "    \n",
    "    # Compute metrics\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_test_binary = label_binarizer.fit_transform(y_test)\n",
    "    y_test_categorical = np.argmax(y_test_binary, axis=1)\n",
    "    y_pred_categorical = np.argmax(y_probs, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_categorical, y_pred_categorical)\n",
    "    precision = precision_score(y_test_categorical, y_pred_categorical, average='weighted')\n",
    "    recall = recall_score(y_test_categorical, y_pred_categorical, average='weighted')\n",
    "    f1 = f1_score(y_test_categorical, y_pred_categorical, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'learning_rate': lr,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'train_loss': cnn_model_history.history['loss'],\n",
    "        'val_loss': cnn_model_history.history['val_loss'],\n",
    "        'train_accuracy': cnn_model_history.history['accuracy'],\n",
    "        'val_accuracy': cnn_model_history.history['val_accuracy']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7d9f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "epochs = range(1, 11)\n",
    "\n",
    "for result in results:\n",
    "    lr = result['learning_rate']\n",
    "    \n",
    "    # Plotting Training and Validation Loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sns.lineplot(epochs, result['train_loss'], label=f'Train Loss (lr={lr})')\n",
    "    sns.lineplot(epochs, result['val_loss'], label=f'Val Loss (lr={lr})')\n",
    "    plt.title(f'Training and Validation Loss for Learning Rate {lr}\\n')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting Training and Validation Accuracy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(epochs, result['train_accuracy'], label=f'Train Accuracy (lr={lr})')\n",
    "    sns.lineplot(epochs, result['val_accuracy'], label=f'Val Accuracy (lr={lr})')\n",
    "    plt.title(f'Training and Validation Accuracy for Learning Rate {lr}\\n')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4957eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final metrics for each learning rate\n",
    "for result in results:\n",
    "    print(f\"Learning Rate: {result['learning_rate']}\")\n",
    "    print(f\"  Accuracy: {result['accuracy']}\")\n",
    "    print(f\"  Precision: {result['precision']}\")\n",
    "    print(f\"  Recall: {result['recall']}\")\n",
    "    print(f\"  F1 Score: {result['f1']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86aafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
